<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Make More Time"><title>spark问题记录 | Ranranran</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">spark问题记录</h1><a id="logo" href="/.">Ranranran</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">spark问题记录</h1><div class="post-meta">May 29, 2018<span> | </span><span class="category"><a href="/categories/spark/">spark</a></span></div><div class="post-content"><h5 id="IDEA运行本地模式spark出现NoClassDefFoundError及NoSuchMethodError错误"><a href="#IDEA运行本地模式spark出现NoClassDefFoundError及NoSuchMethodError错误" class="headerlink" title="IDEA运行本地模式spark出现NoClassDefFoundError及NoSuchMethodError错误"></a>IDEA运行本地模式spark出现NoClassDefFoundError及NoSuchMethodError错误</h5><p>  环境变量中的scala版本与spark依赖的scala版本不同（2.X不同最后一位小版本无影响）会引起此类问题。解决方法：统一这两个版本（目前spark只受scala 2.11.X支持）</p>
<h5 id="Mac下-rtf文件中String转化Int失败"><a href="#Mac下-rtf文件中String转化Int失败" class="headerlink" title="Mac下.rtf文件中String转化Int失败"></a>Mac下.rtf文件中String转化Int失败</h5><p>问题：在macOS下进行spark作业：输出文件中最大及最小数<br>文件结构如下：<br><img src="1.png" alt=""><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.spark.&#123;SparkConf, SparkContext&#125;  </span><br><span class="line"></span><br><span class="line">object MaxAndMin &#123;  </span><br><span class="line">  def main(args: Array[String]): Unit = &#123;  </span><br><span class="line">    val sparkConf = new SparkConf().setMaster(&quot;local&quot;).setAppName(&quot;MaxAndMin&quot;)  </span><br><span class="line">    val sc = new SparkContext(sparkConf)  </span><br><span class="line">    sc.setLogLevel(&quot;ERROR&quot;)  </span><br><span class="line"></span><br><span class="line">    val lines = sc.textFile(&quot;hdfs://localhost:9000/b.txt&quot;)//此处为b.rtf时报错  </span><br><span class="line">    val result = lines.filter(_.trim.length&gt;0).  </span><br><span class="line">      map(line =&gt; (&quot;key&quot;,line.trim.toInt)).//此处报错  </span><br><span class="line">      groupByKey().  </span><br><span class="line">      map(x =&gt; &#123;  </span><br><span class="line">        var max = Integer.MIN_VALUE  </span><br><span class="line">        var min = Integer.MAX_VALUE  </span><br><span class="line">        for(num &lt;- x._2) &#123;  </span><br><span class="line">          if(num &gt; max)  </span><br><span class="line">            max = num  </span><br><span class="line">          if(num &lt; min)  </span><br><span class="line">            min = num  </span><br><span class="line">        &#125;  </span><br><span class="line">        (max,min)  </span><br><span class="line">      &#125;).collect.foreach(x =&gt; &#123;  </span><br><span class="line">      println(&quot;max:\t&quot; + x._1)  </span><br><span class="line">      println(&quot;min:\t&quot; + x._2)  </span><br><span class="line">    &#125;)  </span><br><span class="line"></span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>异常信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)  </span><br><span class="line">java.lang.NumberFormatException: For input string: &quot;&#123;\rtf1\ansi\ansicpg936\cocoartf1561\cocoasubrtf400&quot;  </span><br><span class="line">    at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)  </span><br><span class="line">    at java.lang.Integer.parseInt(Integer.java:580)  </span><br><span class="line">    at java.lang.Integer.parseInt(Integer.java:615)  </span><br><span class="line">    at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)  </span><br><span class="line">    at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)  </span><br><span class="line">    at MaxAndMin$$anonfun$2.apply(MaxAndMin.scala:11)  </span><br><span class="line">    at MaxAndMin$$anonfun$2.apply(MaxAndMin.scala:11)  </span><br><span class="line">    at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)  </span><br><span class="line">    at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:150)  </span><br><span class="line">    at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)  </span><br><span class="line">    at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)  </span><br><span class="line">    at org.apache.spark.scheduler.Task.run(Task.scala:99)  </span><br><span class="line">    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)  </span><br><span class="line">    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)  </span><br><span class="line">    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)  </span><br><span class="line">    at java.lang.Thread.run(Thread.java:748)  </span><br><span class="line">18/06/23 22:27:48 ERROR TaskSetManager: Task 0 in stage 0.0 failed 1 times; aborting job  </span><br><span class="line">Exception in thread &quot;main&quot; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NumberFormatException: For input string: &quot;&#123;\rtf1\ansi\ansicpg936\cocoartf1561\cocoasubrtf400&quot;  </span><br><span class="line">    at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)  </span><br><span class="line">    at java.lang.Integer.parseInt(Integer.java:580)  </span><br><span class="line">    at java.lang.Integer.parseInt(Integer.java:615)  </span><br><span class="line">    at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)  </span><br><span class="line">    at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)  </span><br><span class="line">    at MaxAndMin$$anonfun$2.apply(MaxAndMin.scala:11)  </span><br><span class="line">    at MaxAndMin$$anonfun$2.apply(MaxAndMin.scala:11)  </span><br><span class="line">    at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)  </span><br><span class="line">    at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:150)  </span><br><span class="line">    at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)  </span><br><span class="line">    at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)  </span><br><span class="line">    at org.apache.spark.scheduler.Task.run(Task.scala:99)  </span><br><span class="line">    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)  </span><br><span class="line">    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)  </span><br><span class="line">    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)  </span><br><span class="line">    at java.lang.Thread.run(Thread.java:748)  </span><br><span class="line"></span><br><span class="line">Driver stacktrace:  </span><br><span class="line">    at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)  </span><br><span class="line">    at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423)  </span><br><span class="line">    at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422)  </span><br><span class="line">    at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)  </span><br><span class="line">    at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)  </span><br><span class="line">    at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)  </span><br><span class="line">    at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)  </span><br><span class="line">    at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)  </span><br><span class="line">    at scala.Option.foreach(Option.scala:257)  </span><br><span class="line">    at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)  </span><br><span class="line">    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)  </span><br><span class="line">    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)  </span><br><span class="line">    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)  </span><br><span class="line">    at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)  </span><br><span class="line">    at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)  </span><br><span class="line">    at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)  </span><br><span class="line">    at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)  </span><br><span class="line">    at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)  </span><br><span class="line">    at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958)  </span><br><span class="line">    at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935)  </span><br><span class="line">    at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)  </span><br><span class="line">    at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)  </span><br><span class="line">    at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)  </span><br><span class="line">    at org.apache.spark.rdd.RDD.collect(RDD.scala:934)  </span><br><span class="line">    at MaxAndMin$.main(MaxAndMin.scala:23)  </span><br><span class="line">    at MaxAndMin.main(MaxAndMin.scala)  </span><br><span class="line">Caused by: java.lang.NumberFormatException: For input string: &quot;&#123;\rtf1\ansi\ansicpg936\cocoartf1561\cocoasubrtf400&quot;  </span><br><span class="line">    at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)  </span><br><span class="line">    at java.lang.Integer.parseInt(Integer.java:580)  </span><br><span class="line">    at java.lang.Integer.parseInt(Integer.java:615)  </span><br><span class="line">    at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:272)  </span><br><span class="line">    at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)  </span><br><span class="line">    at MaxAndMin$$anonfun$2.apply(MaxAndMin.scala:11)  </span><br><span class="line">    at MaxAndMin$$anonfun$2.apply(MaxAndMin.scala:11)  </span><br><span class="line">    at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)  </span><br><span class="line">    at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:150)  </span><br><span class="line">    at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)  </span><br><span class="line">    at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)  </span><br><span class="line">    at org.apache.spark.scheduler.Task.run(Task.scala:99)  </span><br><span class="line">    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)  </span><br><span class="line">    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)  </span><br><span class="line">    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)  </span><br><span class="line">    at java.lang.Thread.run(Thread.java:748)</span><br></pre></td></tr></table></figure></p>
<p>可以看到，第十一行的<br><code>map(line =&gt; (&quot;key&quot;,line.trim.toInt)）</code><br>类型转换异常，在什么时候会抛这个异常呢？</p>
<p>在“abc”.toInt时会出现此异常，推测原因是.rtf文件不是一个纯文本格式，.trim()方法消除空格后还存在一些奇怪的东西，所以.toInt会抛异常。</p>
<p>解决方法：用txt格式文件作为源文件。</p>
<p>在macOS下编辑txt：<a href="https://jingyan.baidu.com/article/9158e0002ebe98a25412288c.html" target="_blank" rel="noopener">点击打开链接</a></p>
</div><div class="tags"><a href="/tags/spark/">spark</a></div><div class="post-nav"><a class="pre" href="/2018/05/29/IDEA运行第一个spark（WordCount）/">IDEA运行第一个spark（WordCount）</a><a class="next" href="/2018/05/10/windows下IDEA远程连接Hadoop/">windows下IDEA远程连接Hadoop</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/JSP-Servlet-JDBC开发日记/">JSP+Servlet+JDBC开发日记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/spark/">spark</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/spark实战/">spark实战</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/云计算/">云计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/操作系统/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据结构与算法/">数据结构与算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/组成原理/">组成原理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/网络编程/">网络编程</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算机网络/">计算机网络</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/centos/" style="font-size: 15px;">centos</a> <a href="/tags/spark，IDEA/" style="font-size: 15px;">spark，IDEA</a> <a href="/tags/jsp/" style="font-size: 15px;">jsp</a> <a href="/tags/servlet/" style="font-size: 15px;">servlet</a> <a href="/tags/JDBC/" style="font-size: 15px;">JDBC</a> <a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/分布式/" style="font-size: 15px;">分布式</a> <a href="/tags/spark/" style="font-size: 15px;">spark</a> <a href="/tags/hadoop-错误/" style="font-size: 15px;">hadoop 错误</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/shell/" style="font-size: 15px;">shell</a> <a href="/tags/hadoop，IDEA/" style="font-size: 15px;">hadoop，IDEA</a> <a href="/tags/模式匹配/" style="font-size: 15px;">模式匹配</a> <a href="/tags/Mina/" style="font-size: 15px;">Mina</a> <a href="/tags/基础/" style="font-size: 15px;">基础</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/06/24/Spark实战：统计电影评分/">Spark实战：统计电影评分</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/29/初学Mina/">初学Mina</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/29/IDEA运行第一个spark（WordCount）/">IDEA运行第一个spark（WordCount）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/29/spark问题记录/">spark问题记录</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/10/windows下IDEA远程连接Hadoop/">windows下IDEA远程连接Hadoop</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/09/再谈KMP——KMP的证明及优化/">再谈KMP——KMP的证明及优化</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/08/操作系统知识树/">操作系统知识树</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/08/计算机组成原理知识树/">计算机组成原理知识树</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/08/计算机网络知树/">计算机网络知识树</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/05/hadoop错误汇总/">hadoop错误汇总</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/Deeeeeeepth/" title="My Github" target="_blank">My Github</a><ul></ul><a href="http://www.rxdonny.com/" title="donny's blog" target="_blank">donny's blog</a><ul></ul><a href="http://www.hut.edu.cn/" title="hut" target="_blank">hut</a><ul></ul><a href="http://www.gunpowder.net.cn/" title="gunpowder's" target="_blank">gunpowder's</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">Ranranran.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>